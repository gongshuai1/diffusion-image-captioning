{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-nO5MNtdS1v"
      },
      "source": [
        "# Get preprocessed 'DontPatronizeMe' dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XS1i5FqdS1x",
        "outputId": "991bdbb8-5f10-4fa5-db41-8d26deaf1ee0"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1-gNxTZfDL0aOpzOnxE80M29dUVjSoozn' -O 'train.csv'\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1-cSiEWP_NbDu7fo_7s8O5P163oKLQcBh' -O 'valid.csv'\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1-13l35-18IYPFSV_36llsJbb7c4Gu2o0' -O 'test.csv'\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH5doKeWoxgJ"
      },
      "source": [
        "# Import package, model, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "U6xCt976dS1z",
        "outputId": "090d8988-39aa-4738-b185-37cd2d0f2717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device:  cpu\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "from transformers import (\n",
        "    DistilBertTokenizer, DistilBertForMaskedLM, DistilBertConfig,\n",
        "    BertTokenizer, BertModel as Bert,\n",
        "    activations\n",
        ")\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  dev = \"cuda:0\"\n",
        "else:\n",
        "  dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print(\"using device: \", dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SbAapRyQdS10"
      },
      "outputs": [],
      "source": [
        "# read pandas data\n",
        "train_path = './train.csv'\n",
        "valid_path = './valid.csv'\n",
        "test_path = './test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path).dropna()\n",
        "valid_df = pd.read_csv(valid_path).dropna()\n",
        "test_df = pd.read_csv(test_path).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1Dgq6KK1dS10"
      },
      "outputs": [],
      "source": [
        "# download pretrained model and tokenizer\n",
        "def save_model_tokenizer(tokenizer_class, model_class, name):\n",
        "  tokenizer = tokenizer_class.from_pretrained(name)\n",
        "  tokenizer.save_pretrained(f\"./tokenizers/{name}-local\")\n",
        "  model = model_class.from_pretrained(name)\n",
        "  model.save_pretrained(f\"./models/{name}-local/\")\n",
        "\n",
        "save_model_tokenizer(DistilBertTokenizer, DistilBertForMaskedLM, \"distilbert-base-uncased\")\n",
        "# save_model_tokenizer(BertTokenizer, Bert, \"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drw9XZ_GdS11"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "chPgGq3bdS12"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "batch_size = 16\n",
        "max_length = 128 # max text length\n",
        "learning_rate = 5e-5\n",
        "epoch_num = 2\n",
        "linear_probe = False\n",
        "\n",
        "# diffusion hyperparameter\n",
        "beta_min = 0.0001\n",
        "beta_max = 0.02\n",
        "step_tot = 2000 # total noise adding steps\n",
        "sample_size = 1 # number of sample steps in each diffuse sequence TODO: suspect can only be 1, otherwise mask is wrong\n",
        "train_embedding = False # if embedding is trainable or random gaussian initialize, TODO: why diffusion lm can have term as lernable, cause collaps\n",
        "x_0_prediction = True # if model predicts x_0 or x_{t-1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZwRatWVdS13"
      },
      "source": [
        "# Model, trainer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA6YHlL7jIt-",
        "outputId": "cc634fb2-8429-4086-aba3-cf311f66b6d8"
      },
      "outputs": [],
      "source": [
        "class DistilBertModel(nn.Module):\n",
        "  def __init__(self, embedding, projection, train_embedding=True, config=None) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # self.model = DistilBertForMaskedLM.from_pretrained(\"./models/distilbert-base-uncased-local\", local_files_only=True, config=config).to(device)\n",
        "    self.model = DistilBertForMaskedLM(config).to(device)\n",
        "    \n",
        "    self.embedding = copy.deepcopy(embedding.requires_grad_(train_embedding))\n",
        "    self.projection = copy.deepcopy(projection.requires_grad_(train_embedding))\n",
        "    self.projection.bias.data = torch.zeros(self.projection.bias.data.shape, device=device)\n",
        "    self.model.set_input_embeddings(nn.Sequential())\n",
        "    self.model.set_output_embeddings(nn.Sequential())\n",
        "\n",
        "    # print(self.model.config)\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.model.parameters()\n",
        "    # return list(model.model.parameters()) + list(model.embedding.parameters()) + list(model.projection.parameters())\n",
        "  \n",
        "  def forward(self, x, mask):\n",
        "    '''\n",
        "    return \n",
        "      feature_out, shape: [batch_size, seq_len, dim]\n",
        "      vocab_out, shape: [batch_size, seq_len, vocab_size]\n",
        "    '''\n",
        "    \n",
        "    x_out = self.model(x, mask)[0]\n",
        "    return self.projection(x_out), x_out\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "  def __init__(self, embedding, projection, train_embedding=True, config=None) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # self.model = DistilBertForMaskedLM.from_pretrained(\"./models/distilbert-base-uncased-local\", local_files_only=True, config=config).to(device)\n",
        "    self.model = nn.Linear(768, 768).to(device)\n",
        "    \n",
        "    self.embedding = copy.deepcopy(embedding.requires_grad_(train_embedding))\n",
        "    self.projection = copy.deepcopy(projection.requires_grad_(train_embedding))\n",
        "    self.projection.bias.data = torch.zeros(self.projection.bias.data.shape, device=device)\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.model.parameters()\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    hidden = self.model(x)\n",
        "    return self.projection(hidden), hidden\n",
        "    \n",
        "origin = DistilBertForMaskedLM.from_pretrained(\"./models/distilbert-base-uncased-local\", local_files_only=True).to(device)\n",
        "\n",
        "configuration = DistilBertConfig()\n",
        "model = DistilBertModel(origin.get_input_embeddings(), origin.get_output_embeddings(), train_embedding=train_embedding, config=configuration)\n",
        "# model = EncoderModel(train_embedding=train_embedding)\n",
        "# model = BertModel(train_embedding=train_embedding)\n",
        "# model = LinearModel(origin.get_input_embeddings(), origin.get_output_embeddings(), train_embedding=train_embedding)\n",
        "\n",
        "if linear_probe:  \n",
        "  # TODO: linear probation not supported\n",
        "  NotImplementedError()\n",
        "  # trainer = optim.Adam(model.projection.parameters(), lr=learning_rate)\n",
        "else:\n",
        "  # parameter only include model, no embedding layer\n",
        "  # trainer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  trainer = optim.AdamW(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "KNtrwcxDdS13"
      },
      "outputs": [],
      "source": [
        "betas = torch.hstack([torch.zeros(1), torch.linspace(beta_min, beta_max, step_tot)]).to(device)\n",
        "alphas = 1 - betas\n",
        "alpha_cumprod = torch.cumprod(alphas[:-1], 0)\n",
        "def diffuse_t(x, t):\n",
        "  '''\n",
        "  x_shape: [batch_size, seq_len, dim]\n",
        "  t shape: [sample num]\n",
        "\n",
        "  return shape [batch_size * sample_num, seq_len, dim]\n",
        "  '''\n",
        "  # TODO: change model to use different noise\n",
        "  batch_size, seq_len, dim = x.shape\n",
        "  sample_shape = (sample_size, *(1, ) * len(x.shape))\n",
        "\n",
        "  noise = torch.normal(0, 1, x.shape).to(device)\n",
        "  mean = torch.sqrt(alpha_cumprod[t].reshape(sample_shape)) * x \n",
        "  epsilon = noise * torch.sqrt(1 - alpha_cumprod[t]).reshape(sample_shape)\n",
        "  return (mean + epsilon).reshape((sample_size * batch_size, seq_len, dim))\n",
        "\n",
        "def generate_diffuse_pair(x_0, repeat_shape, t, t_next=-1):\n",
        "  '''\n",
        "  x_0 shape: [batch_size, seq_len, dim]\n",
        "  t shape: [sample_num]\n",
        "  repeat shape: (sample_num, 1, 1, ...)\n",
        "  \n",
        "  return (net input, net target)\n",
        "    shape [batch_size * sample_num, seq_len, dim]\n",
        "  '''\n",
        "  if t_next == -1:\n",
        "    # predict x_0\n",
        "    return (diffuse_t(x_0, t), x_0.repeat(repeat_shape))\n",
        "\n",
        "  # predict x_{t_next}\n",
        "  return (diffuse_t(x_0, t), diffuse_t(x_0, t_next))\n",
        "\n",
        "def loss(model, x_t, x_1, x_0, mask, idx, loss_func):\n",
        "  ''' \n",
        "  input: \n",
        "    model,\n",
        "    x_t, x_1, x_0 shape: [batch_size, seq_len, dim]\n",
        "    mask\n",
        "    seq shape: [batch_size, seq_len]TODO: seq only support one sample\n",
        "    loss_func\n",
        "  '''\n",
        "  _, x_hat = model(x_t, mask)\n",
        "\n",
        "  probability, x_0_hat = model(x_1, mask)\n",
        "\n",
        "  idx = idx.unsqueeze(dim=-1)\n",
        "  seq_probability_loss = -(nn.functional.softmax(probability, dim=-1)).gather(-1, idx).log().mean()\n",
        "  \n",
        "  return loss_func(x_hat, x_0), loss_func(x_0_hat, x_0), 0.1 * seq_probability_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRU8CjtXdS15"
      },
      "source": [
        "# Define dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "6r_AmkWadS15"
      },
      "outputs": [],
      "source": [
        "# define dataset \n",
        "class DPMDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, input_df):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = input_df['text'].tolist()\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        # function for batch allocation\n",
        "        texts = []\n",
        "\n",
        "        for b in batch:\n",
        "            texts.append(b)\n",
        "\n",
        "        encodings = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length)\n",
        "\n",
        "        return {\"input_ids\": encodings[\"input_ids\"].to(device), \"attention_mask\": encodings[\"attention_mask\"].to(device)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"./tokenizers/distilbert-base-uncased-local/\", local_files_only=True)\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"./tokenizers/bert-base-cased-local\", local_files_only=True)\n",
        "\n",
        "train_dataset = DPMDataset(tokenizer, train_df)\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=train_dataset.collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Lj9pKtdS16"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GApc9yMOdS16",
        "outputId": "0fdd14f7-3578-4036-c2a1-1a2b31552d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 174:   3%|▎         | 175/6700 [00:09<05:57, 18.27batch/s, tot_loss=0.00151, x_1_restore=0.00151]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=18'>19</a>\u001b[0m x_1_tgt \u001b[39m=\u001b[39m diffuse_t(x_0, torch\u001b[39m.\u001b[39mones(\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mrepeat(repeat_shape))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=20'>21</a>\u001b[0m trainer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=21'>22</a>\u001b[0m x_t_restore, x_1_restore \u001b[39m=\u001b[39m loss(model, x_input, x_1_tgt, x_0, x[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mrepeat(repeat_shape), nn\u001b[39m.\u001b[39;49mMSELoss())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=22'>23</a>\u001b[0m l \u001b[39m=\u001b[39m x_t_restore \u001b[39m+\u001b[39m x_1_restore\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=23'>24</a>\u001b[0m l\u001b[39m.\u001b[39mbackward()\n",
            "\u001b[1;32m/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb Cell 15\u001b[0m in \u001b[0;36mloss\u001b[0;34m(model, x_t, x_1, x_0, mask, loss_func)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=36'>37</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=37'>38</a>\u001b[0m \u001b[39minput: \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=38'>39</a>\u001b[0m \u001b[39m  model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=41'>42</a>\u001b[0m \u001b[39m  loss_func\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=42'>43</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=43'>44</a>\u001b[0m \u001b[39m# _, x_hat = model(x_t, mask)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=45'>46</a>\u001b[0m _, x_0_hat \u001b[39m=\u001b[39m model(x_1, mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=47'>48</a>\u001b[0m \u001b[39m# seq_probability_loss = -torch.max(nn.functional.softmax(probability, dim=-1), dim=-1)[0].log().mean()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=48'>49</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=49'>50</a>\u001b[0m \u001b[39m# return loss_func(x_hat, x_0), loss_func(x_0_hat, x_0)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m, loss_func(x_0_hat, x_0)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb Cell 15\u001b[0m in \u001b[0;36mLinearModel.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=93'>94</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, mask):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=94'>95</a>\u001b[0m   hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000014?line=95'>96</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprojection(hidden), hidden\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# training\n",
        "# model = torch.load(\"model_continue1.pickle\")[\"net\"]\n",
        "# trainer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "model.train()\n",
        "print(\"start training\")\n",
        "for epoch in range(epoch_num):\n",
        "  acc_loss = 0\n",
        "  with tqdm.tqdm(train_loader, unit=\"batch\") as tepoch: \n",
        "    for epoch, x in enumerate(tepoch):\n",
        "  # for x in train_loader:\n",
        "      x_0 = model.embedding(x[\"input_ids\"])\n",
        "      repeat_shape = (sample_size, *(1, ) * (len(x_0.shape) - 1))\n",
        "      t = torch.randint(0, step_tot, repeat_shape, device=device)\n",
        "      if x_0_prediction:\n",
        "        x_input, x_tgt = generate_diffuse_pair(x_0, repeat_shape, t)\n",
        "      else:\n",
        "        print(\"not implemented\")\n",
        "        # x_input, x_tgt = generate_diffuse_pair(x_0, repeat_shape, t, torch.max(t - 30, 0))\n",
        "      x_1_tgt = diffuse_t(x_0, torch.ones(1, dtype=torch.int64, device=device).repeat(repeat_shape))\n",
        "\n",
        "      trainer.zero_grad()\n",
        "      x_t_restore, x_1_restore, prob = loss(model, x_input, x_1_tgt, x_0, x[\"attention_mask\"].repeat(repeat_shape), x[\"input_ids\"], nn.L1Loss())\n",
        "      l = x_t_restore + x_1_restore + prob\n",
        "      l.backward()\n",
        "      trainer.step()\n",
        "\n",
        "      acc_loss += l\n",
        "\n",
        "      tepoch.set_description(f\"Epoch {epoch}\")\n",
        "      tepoch.set_postfix(\n",
        "                        x_t_restore=x_t_restore.item(),\n",
        "                         x_1_restore=x_1_restore.item(),\n",
        "                         prob=prob.item(),\n",
        "                         tot_loss=l.item())\n",
        "\n",
        "  print(f\"epoch {epoch} average loss: {acc_loss / len(train_loader)}, last loss x_t_restore, x_1_restore, prob: {x_t_restore, x_1_restore, prob}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoVoUgi4dS17",
        "outputId": "c9580a2e-a6c2-4d9c-fb47-ad64811ec497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "origin text:  Critics have even taken to dobbing in Katrina Bungard to National Party leader Bill English when they see her sign-written car bearing her name and photo parked in disabled parks .\n",
            "noise added\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "loss (0, tensor(0.0001, grad_fn=<MseLossBackward0>))\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "loss (0, tensor(0.0001, grad_fn=<MseLossBackward0>))\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "loss (0, tensor(0.0001, grad_fn=<MseLossBackward0>))\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "loss (0, tensor(0.0001, grad_fn=<MseLossBackward0>))\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "inferred:  [CLS] critics have even taken to dobbing in katrina bungard to national party leader bill english when they see her sign - written car bearing her name and photo parked in disabled parks. [SEP]\n",
            "loss (0, tensor(0.0001, grad_fn=<MseLossBackward0>))\n"
          ]
        }
      ],
      "source": [
        "# trial on inference\n",
        "# model = torch.load(\"model_continue1.pickle\")[\"net\"]\n",
        "# model.model.add_module(\"activation\", activations.GELUActivation())\n",
        "# model.model.weight.data = torch.eye(768).\n",
        "# model.model.bias.data = torch.zeros(model.model.bias.data.shape)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "origin_text = train_df.loc[11][\"text\"]\n",
        "text = tokenizer(origin_text, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device)\n",
        "print(\"origin text: \", origin_text)\n",
        "\n",
        "x_0 = model.embedding(text[\"input_ids\"])\n",
        "repeat_shape = (sample_size, *(1, ) * (len(x_0.shape) - 1))\n",
        "t = torch.randint(0, step_tot, repeat_shape, device=device)\n",
        "\n",
        "noised_text = diffuse_t(x_0, t)\n",
        "# x_1 = diffuse_t(x_0, torch.ones(1, dtype=torch.int64, device=device).repeat(repeat_shape))\n",
        "x_t = diffuse_t(x_0, torch.tensor([25], dtype=torch.int64, device=device).repeat(repeat_shape))\n",
        "print(\"noise added\")\n",
        "print(\"t\", t)\n",
        "print(\"x_0 ground truth: \", tokenizer.decode((x_0 @ model.projection.weight.data.T).argmax(dim=-1)[0]))\n",
        "\n",
        "# multi-step inference\n",
        "restored = x_t\n",
        "for i in range(5):\n",
        "  out, restored = model(restored, text[\"attention_mask\"].repeat(repeat_shape)) \n",
        "\n",
        "  # print(\"inferred: \", tokenizer.decode(torch.softmax(out, dim=-1).argmax(dim=-1)[0]))\n",
        "  print(\"inferred: \", tokenizer.decode(out.argmax(dim=-1)[0]))\n",
        "  # print(\"loss\", loss(model, noised_text, x_1, x_0.repeat(repeat_shape), text[\"attention_mask\"].repeat(repeat_shape), text[\"input_ids\"], nn.L1Loss()))\n",
        "\n",
        "print(\"text t effectiveness\")\n",
        "# effectiveness of model on large t\n",
        "for i in range(5, 500, 25):\n",
        "  x_t = diffuse_t(x_0, torch.tensor([i], dtype=torch.int64, device=device).repeat(repeat_shape))\n",
        "  out, _ = model(x_t, text[\"attention_mask\"].repeat(repeat_shape)) \n",
        "\n",
        "  # print(\"inferred: \", tokenizer.decode(torch.softmax(out, dim=-1).argmax(dim=-1)[0]))\n",
        "  print(\"t: \", i, \"restore: \", tokenizer.decode(out.argmax(dim=-1)[0]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H61Lo_yNdS17"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "torch.save({\"net\": model.to(torch.device(\"cpu\"))}, \"model.pickle\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l-nO5MNtdS1v",
        "NRU8CjtXdS15",
        "65Lj9pKtdS16"
      ],
      "name": "main.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('mlenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1f93c46dd61ce6925df2c3958a0a88f8277015b6331ee5021fc1dcace5372220"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

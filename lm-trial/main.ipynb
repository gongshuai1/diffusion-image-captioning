{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-nO5MNtdS1v"
      },
      "source": [
        "# Get preprocessed 'DontPatronizeMe' dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XS1i5FqdS1x",
        "outputId": "991bdbb8-5f10-4fa5-db41-8d26deaf1ee0"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1-gNxTZfDL0aOpzOnxE80M29dUVjSoozn' -O 'train.csv'\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1-cSiEWP_NbDu7fo_7s8O5P163oKLQcBh' -O 'valid.csv'\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1-13l35-18IYPFSV_36llsJbb7c4Gu2o0' -O 'test.csv'\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH5doKeWoxgJ"
      },
      "source": [
        "# Import package, model, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "U6xCt976dS1z",
        "outputId": "090d8988-39aa-4738-b185-37cd2d0f2717"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/xushitong/miniconda3/envs/mlenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device:  cpu\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "from transformers import (\n",
        "    DistilBertTokenizer, DistilBertForMaskedLM, DistilBertConfig,\n",
        "    BertTokenizer, BertModel as Bert,\n",
        "    activations\n",
        ")\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  dev = \"cuda:0\"\n",
        "else:\n",
        "  dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print(\"using device: \", dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SbAapRyQdS10"
      },
      "outputs": [],
      "source": [
        "# read pandas data\n",
        "train_path = './train.csv'\n",
        "valid_path = './valid.csv'\n",
        "test_path = './test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path).dropna()\n",
        "valid_df = pd.read_csv(valid_path).dropna()\n",
        "test_df = pd.read_csv(test_path).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Dgq6KK1dS10"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000005?line=4'>5</a>\u001b[0m   model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39mfrom_pretrained(name)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000005?line=5'>6</a>\u001b[0m   model\u001b[39m.\u001b[39msave_pretrained(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m-local/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000005?line=7'>8</a>\u001b[0m save_model_tokenizer(DistilBertTokenizer, DistilBertForMaskedLM, \u001b[39m\"\u001b[39;49m\u001b[39mdistilbert-base-uncased\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "\u001b[1;32m/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb Cell 6\u001b[0m in \u001b[0;36msave_model_tokenizer\u001b[0;34m(tokenizer_class, model_class, name)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000005?line=2'>3</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(name)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000005?line=3'>4</a>\u001b[0m tokenizer\u001b[39m.\u001b[39msave_pretrained(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./tokenizers/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m-local\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000005?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(name)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xushitong/diffusion-image-captioning/lm-trial/main.ipynb#ch0000005?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39msave_pretrained(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m-local/\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/transformers/modeling_utils.py:1833\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   1832\u001b[0m     config_path \u001b[39m=\u001b[39m config \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 1833\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m   1834\u001b[0m         config_path,\n\u001b[1;32m   1835\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1836\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1837\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1838\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1839\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1840\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1841\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1842\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1843\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   1844\u001b[0m         _from_auto\u001b[39m=\u001b[39;49mfrom_auto_class,\n\u001b[1;32m   1845\u001b[0m         _from_pipeline\u001b[39m=\u001b[39;49mfrom_pipeline,\n\u001b[1;32m   1846\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1847\u001b[0m     )\n\u001b[1;32m   1848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1849\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/transformers/configuration_utils.py:534\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPretrainedConfig\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    459\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[39m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    535\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type:\n\u001b[1;32m    536\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    537\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are using a model of type \u001b[39m\u001b[39m{\u001b[39;00mconfig_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to instantiate a model of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         )\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/transformers/configuration_utils.py:561\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    560\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    563\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/transformers/configuration_utils.py:616\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m         config_file \u001b[39m=\u001b[39m hf_bucket_url(\n\u001b[1;32m    607\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m    608\u001b[0m             filename\u001b[39m=\u001b[39mconfiguration_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m             mirror\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    612\u001b[0m         )\n\u001b[1;32m    614\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m    617\u001b[0m         config_file,\n\u001b[1;32m    618\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    619\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    620\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    621\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    622\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    623\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    624\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[1;32m    627\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    628\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    629\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier listed on \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    630\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to pass a token having \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpermission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    280\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    285\u001b[0m         url_or_filename,\n\u001b[1;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/transformers/utils/hub.py:501\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m local_files_only:\n\u001b[1;32m    500\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m         r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mhead(url, headers\u001b[39m=\u001b[39;49mheaders, allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, proxies\u001b[39m=\u001b[39;49mproxies, timeout\u001b[39m=\u001b[39;49metag_timeout)\n\u001b[1;32m    502\u001b[0m         _raise_for_status(r)\n\u001b[1;32m    503\u001b[0m         etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/requests/api.py:100\u001b[0m, in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a HEAD request.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 100\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mhead\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[1;32m   1045\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1046\u001b[0m         (\n\u001b[1;32m   1047\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1053\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/urllib3/connection.py:414\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    406\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_certs\n\u001b[1;32m    407\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(context, \u001b[39m\"\u001b[39m\u001b[39mload_default_certs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    411\u001b[0m ):\n\u001b[1;32m    412\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[0;32m--> 414\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[1;32m    415\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[1;32m    416\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[1;32m    417\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[1;32m    418\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[1;32m    419\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[1;32m    420\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[1;32m    421\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[1;32m    422\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    423\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[1;32m    424\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[1;32m    425\u001b[0m )\n\u001b[1;32m    427\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    431\u001b[0m     default_ssl_context\n\u001b[1;32m    432\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock, \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    434\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock\u001b[39m.\u001b[39mversion() \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mTLSv1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTLSv1.1\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    435\u001b[0m ):\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/urllib3/util/ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    437\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    438\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         SNIMissingWarning,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[0;32m--> 449\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[1;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39;49mserver_hostname\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/site-packages/urllib3/util/ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[39mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m    492\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n\u001b[1;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39mwrap_socket(sock)\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    501\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    502\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    503\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    504\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    505\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    506\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    507\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    508\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m   1038\u001b[0m             \u001b[39m# non-blocking\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1041\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
            "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.9/ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mand\u001b[39;00m block:\n\u001b[1;32m   1308\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1310\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(timeout)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# download pretrained model and tokenizer\n",
        "def save_model_tokenizer(tokenizer_class, model_class, name):\n",
        "  tokenizer = tokenizer_class.from_pretrained(name)\n",
        "  tokenizer.save_pretrained(f\"./tokenizers/{name}-local\")\n",
        "  model = model_class.from_pretrained(name)\n",
        "  model.save_pretrained(f\"./models/{name}-local/\")\n",
        "\n",
        "save_model_tokenizer(DistilBertTokenizer, DistilBertForMaskedLM, \"distilbert-base-uncased\")\n",
        "# save_model_tokenizer(BertTokenizer, Bert, \"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drw9XZ_GdS11"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "chPgGq3bdS12"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "MAX_LENGTH = 128 # max text length\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCH_NUM = 3\n",
        "ROUNDING_WEIGHT = 0.05 # weight of rounding term, the probability of regenerated sequence \n",
        "\n",
        "# diffusion hyperparameter\n",
        "BETA_MIN = 0.0001\n",
        "BETA_MAX = 0.02\n",
        "STEP_TOT = 2000 # total noise adding steps\n",
        "SAMPLE_SIZE = 3 # number of sample steps in each diffuse sequence\n",
        "TRAIN_EMBEDDING = False # if embedding is trainable or random gaussian initialize, TODO: why diffusion lm can have term as lernable, cause collaps\n",
        "X_0_PREDICTION = True # if model predicts x_0 or x_{t-1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZwRatWVdS13"
      },
      "source": [
        "# Model, trainer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA6YHlL7jIt-",
        "outputId": "cc634fb2-8429-4086-aba3-cf311f66b6d8"
      },
      "outputs": [],
      "source": [
        "class DistilBertModel(nn.Module):\n",
        "  def __init__(self, embedding, projection, train_embedding=True, config=None) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = DistilBertForMaskedLM(config).to(device)\n",
        "    \n",
        "    self.embedding = copy.deepcopy(embedding.requires_grad_(train_embedding))\n",
        "    self.projection = copy.deepcopy(projection.requires_grad_(train_embedding))\n",
        "    self.projection.bias.data = torch.zeros(self.projection.bias.data.shape, device=device)\n",
        "    self.model.set_input_embeddings(nn.Sequential())\n",
        "    self.model.set_output_embeddings(nn.Sequential())\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.model.parameters()\n",
        "    # return list(model.model.parameters()) + list(model.embedding.parameters()) + list(model.projection.parameters())\n",
        "  \n",
        "  def forward(self, x, mask):\n",
        "    '''\n",
        "    return \n",
        "      feature_out, shape: [batch_size, seq_len, dim]\n",
        "      vocab_out, shape: [batch_size, seq_len, vocab_size]\n",
        "    '''\n",
        "    \n",
        "    x_out = self.model(x, mask)[0]\n",
        "    return self.projection(x_out), x_out\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "  def __init__(self, embedding, projection, train_embedding=True, config=None) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = nn.Linear(768, 768).to(device)\n",
        "    \n",
        "    self.embedding = copy.deepcopy(embedding.requires_grad_(train_embedding))\n",
        "    self.projection = copy.deepcopy(projection.requires_grad_(train_embedding))\n",
        "    self.projection.bias.data = torch.zeros(self.projection.bias.data.shape, device=device)\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.model.parameters()\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    hidden = self.model(x)\n",
        "    return self.projection(hidden), hidden\n",
        "    \n",
        "origin = DistilBertForMaskedLM.from_pretrained(\"./models/distilbert-base-uncased-local\", local_files_only=True).to(device)\n",
        "\n",
        "configuration = DistilBertConfig()\n",
        "model = DistilBertModel(origin.get_input_embeddings(), origin.get_output_embeddings(), train_embedding=TRAIN_EMBEDDING, config=configuration)\n",
        "# model = EncoderModel(train_embedding=TRAIN_EMBEDDING)\n",
        "# model = BertModel(train_embedding=TRAIN_EMBEDDING)\n",
        "# model = LinearModel(origin.get_input_embeddings(), origin.get_output_embeddings(), train_embedding=TRAIN_EMBEDDING)\n",
        "\n",
        "# parameter only include model, no embedding layer\n",
        "# trainer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "trainer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KNtrwcxDdS13"
      },
      "outputs": [],
      "source": [
        "betas = torch.hstack([torch.zeros(1), torch.linspace(BETA_MIN, BETA_MAX, STEP_TOT)]).to(device)\n",
        "alphas = 1 - betas\n",
        "alpha_cumprod = torch.cumprod(alphas[:-1], 0)\n",
        "def diffuse_t(x, t):\n",
        "  '''\n",
        "  x_shape: [batch_size, seq_len, dim]\n",
        "  t shape: [sample num] NOTE: not necessary have hyperparameter sample_size number of element, to allow single diffuse generation\n",
        "\n",
        "  return shape [sample_num * batch_size, seq_len, dim]\n",
        "  '''\n",
        "  batch_size, seq_len, dim = x.shape\n",
        "  sample_shape = (t.numel(), *(1, ) * len(x.shape))\n",
        "\n",
        "  noise = torch.normal(0, 1, x.shape).to(device)\n",
        "  mean = torch.sqrt(alpha_cumprod[t].reshape(sample_shape)) * x \n",
        "  epsilon = noise * torch.sqrt(1 - alpha_cumprod[t]).reshape(sample_shape)\n",
        "  return (mean + epsilon).reshape((t.numel() * batch_size, seq_len, dim))\n",
        "\n",
        "def generate_diffuse_pair(x_0, t, t_next=None):\n",
        "  '''\n",
        "  x_0 shape: [batch_size, seq_len, dim]\n",
        "  t shape: [sample_num] NOTE: not necessary have hyperparameter sample_size number of element, to allow single diffuse generation\n",
        "  \n",
        "  return (net input, net target)\n",
        "    shape [sample_num * batch_size, seq_len, dim]\n",
        "  '''\n",
        "  if t_next is None:\n",
        "    # predict x_0\n",
        "    return (diffuse_t(x_0, t), x_0)\n",
        "\n",
        "  # predict x_{t_next}\n",
        "  return (diffuse_t(x_0, t), diffuse_t(x_0, t_next))\n",
        "\n",
        "def loss(model, x_t, x_1, x_0, mask, idx, loss_func):\n",
        "  ''' \n",
        "  input: \n",
        "    model,\n",
        "    x_t shape: [sample_num * batch_size, seq_len, dim]\n",
        "    x_1, x_0 shape: [batch_size, seq_len, dim]\n",
        "    mask shape: [batch_size, seq_len]\n",
        "    idx shape: [batch_size, seq_len]\n",
        "    loss_func\n",
        "  '''\n",
        "  \n",
        "  repeat_shape = (SAMPLE_SIZE, *(1, ) * (len(x_t.shape) - 1))\n",
        "\n",
        "  x_t_prob, x_t_hidden = model(x_t, mask.repeat(repeat_shape))\n",
        "\n",
        "  x_1_prob, x_1_hidden = model(x_1, mask)\n",
        "\n",
        "  idx = idx.unsqueeze(dim=-1)\n",
        "  x_t_prob_loss = -(nn.functional.softmax(x_t_prob, dim=-1)).gather(-1, idx.repeat(repeat_shape)).log().mean()\n",
        "  x_1_prob_loss = -(nn.functional.softmax(x_1_prob, dim=-1)).gather(-1, idx).log().mean()\n",
        "  \n",
        "  return loss_func(x_t_hidden, x_0.repeat(repeat_shape)), loss_func(x_1_hidden, x_0), ROUNDING_WEIGHT * (x_t_prob_loss + x_1_prob_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRU8CjtXdS15"
      },
      "source": [
        "# Define dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6r_AmkWadS15"
      },
      "outputs": [],
      "source": [
        "# define dataset \n",
        "class DPMDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, input_df):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = input_df['text'].tolist()\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        # function for batch allocation\n",
        "        texts = []\n",
        "\n",
        "        for b in batch:\n",
        "            texts.append(b)\n",
        "\n",
        "        encodings = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "        return {\"input_ids\": encodings[\"input_ids\"].to(device), \"attention_mask\": encodings[\"attention_mask\"].to(device)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"./tokenizers/distilbert-base-uncased-local/\", local_files_only=True)\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"./tokenizers/bert-base-cased-local\", local_files_only=True)\n",
        "\n",
        "train_dataset = DPMDataset(tokenizer, train_df)\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=train_dataset.collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Lj9pKtdS16"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GApc9yMOdS16",
        "outputId": "0fdd14f7-3578-4036-c2a1-1a2b31552d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/419 [00:40<?, ?batch/s, prob_loss=1.08, tot_loss=2.59, x_1_loss=0.758, x_t_hidden=0.76]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 average loss: 0.006189580541104078, last loss x_t_loss, x_1_loss, prob_loss: (tensor(0.7598, grad_fn=<L1LossBackward0>), tensor(0.7584, grad_fn=<L1LossBackward0>), tensor(1.0752, grad_fn=<MulBackward0>))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "# model = torch.load(\"model_continue1.pickle\")[\"net\"]\n",
        "# trainer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "model.train()\n",
        "print(\"start training\")\n",
        "for epoch in range(EPOCH_NUM):\n",
        "  acc_loss = 0\n",
        "  with tqdm.tqdm(train_loader, unit=\"batch\") as tepoch: \n",
        "    for epoch, x in enumerate(tepoch):\n",
        "  # for x in train_loader:\n",
        "      x_0 = model.embedding(x[\"input_ids\"])\n",
        "      repeat_shape = (SAMPLE_SIZE, *(1, ) * (len(x_0.shape) - 1))\n",
        "      t = torch.randint(0, STEP_TOT, repeat_shape, device=device)\n",
        "      if X_0_PREDICTION:\n",
        "        x_t = diffuse_t(x_0, t)\n",
        "      else:\n",
        "        print(\"not implemented\")\n",
        "        # x_input, x_tgt = generate_diffuse_pair(x_0, repeat_shape, t, torch.max(t - 30, 0))\n",
        "      x_1 = diffuse_t(x_0, torch.ones(1, dtype=torch.int64, device=device))\n",
        "\n",
        "      trainer.zero_grad()\n",
        "      x_t_loss, x_1_loss, prob_loss = loss(model, x_t, x_1, x_0, x[\"attention_mask\"], x[\"input_ids\"], nn.L1Loss())\n",
        "      l = x_t_loss + x_1_loss + prob_loss\n",
        "      l.backward()\n",
        "      trainer.step()\n",
        "\n",
        "      acc_loss += l\n",
        "\n",
        "      tepoch.set_description(f\"Epoch {epoch}\")\n",
        "      tepoch.set_postfix(\n",
        "                         x_t_hidden=x_t_loss.item(),\n",
        "                         x_1_loss=x_1_loss.item(),\n",
        "                         prob_loss=prob_loss.item(),\n",
        "                         tot_loss=l.item())\n",
        "      break\n",
        "\n",
        "  print(f\"epoch {epoch} average loss: {acc_loss / len(train_loader)}, last loss x_t_loss, x_1_loss, prob_loss: {x_t_loss, x_1_loss, prob_loss}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoVoUgi4dS17",
        "outputId": "c9580a2e-a6c2-4d9c-fb47-ad64811ec497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "origin text:  B.C. housing minister Selina Robinson said that the project represents hope for many women and families in need .\n",
            "noise added\n",
            "t tensor([[[1465]],\n",
            "\n",
            "        [[1200]]])\n",
            "x_0 ground truth:  [CLS] b.rdon. housing minister selinaomba 690 that the project represents hope for many women and families in need. [SEP]\n",
            "inferred:  [CLS] b. a. housing minister se \" [SEP] said that ‖ project is hope for many women and families in need. [SEP]\n",
            "inferred:  [CLS] in [SEP] in [SEP] high his in \" [SEP] his that ‖ \" is \" for in [SEP] and [SEP] in models [SEP] [SEP]\n",
            "inferred:  ##aint buena hapoelorf hapoel buenaviere buena buena hapoel hapoel buenaviere buena buenaviere buenaviere hapoel buena hapoel buenaaint hapoel hapoel\n",
            "inferred:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "inferred:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "text t effectiveness\n",
            "t:  5 restore:  [CLS] b. c. housing minister selina robinson said that the project represents hope for many women and families in need. [SEP]\n",
            "t:  30 restore:  [CLS] b. a. housing minister for [CLS] in said that the project [CLS] hope for many women and families in need. [SEP]\n",
            "t:  55 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  80 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  105 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  130 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  155 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  180 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  205 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  230 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  255 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  280 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  305 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  330 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  355 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  380 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  405 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  430 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  455 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n",
            "t:  480 restore:  ##viereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviereviere\n"
          ]
        }
      ],
      "source": [
        "# trial on inference\n",
        "model = torch.load(\"model_1.pickle\")[\"net\"].to(device)\n",
        "\n",
        "model.eval()\n",
        "origin_text = train_df.loc[11][\"text\"]\n",
        "text = tokenizer(origin_text, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LENGTH).to(device)\n",
        "print(\"origin text: \", origin_text)\n",
        "\n",
        "x_0 = model.embedding(text[\"input_ids\"])\n",
        "repeat_shape = (SAMPLE_SIZE, *(1, ) * (len(x_0.shape) - 1))\n",
        "t = torch.randint(0, STEP_TOT, repeat_shape, device=device)\n",
        "\n",
        "noised_text = diffuse_t(x_0, t)\n",
        "# x_1 = diffuse_t(x_0, torch.ones(1, dtype=torch.int64, device=device).repeat(repeat_shape))\n",
        "x_t = diffuse_t(x_0, torch.tensor([25], dtype=torch.int64, device=device).repeat(repeat_shape))\n",
        "print(\"noise added\")\n",
        "print(\"t\", t)\n",
        "print(\"x_0 ground truth: \", tokenizer.decode((x_0 @ model.projection.weight.data.T).argmax(dim=-1)[0]))\n",
        "\n",
        "# multi-step inference\n",
        "restored = x_t\n",
        "for i in range(5):\n",
        "  out, restored = model(restored, text[\"attention_mask\"].repeat(repeat_shape)) \n",
        "\n",
        "  # print(\"inferred: \", tokenizer.decode(torch.softmax(out, dim=-1).argmax(dim=-1)[0]))\n",
        "  print(\"inferred: \", tokenizer.decode(out.argmax(dim=-1)[0]))\n",
        "  # print(\"loss\", loss(model, noised_text, x_1, x_0.repeat(repeat_shape), text[\"attention_mask\"].repeat(repeat_shape), text[\"input_ids\"], nn.L1Loss()))\n",
        "\n",
        "print(\"text t effectiveness\")\n",
        "# effectiveness of model on large t\n",
        "for i in range(5, 500, 25):\n",
        "  x_t = diffuse_t(x_0, torch.tensor([i], dtype=torch.int64, device=device).repeat(repeat_shape))\n",
        "  out, _ = model(x_t, text[\"attention_mask\"].repeat(repeat_shape)) \n",
        "\n",
        "  # print(\"inferred: \", tokenizer.decode(torch.softmax(out, dim=-1).argmax(dim=-1)[0]))\n",
        "  print(\"t: \", i, \"restore: \", tokenizer.decode(out.argmax(dim=-1)[0]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H61Lo_yNdS17"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "torch.save({\"net\": model.to(torch.device(\"cpu\"))}, \"model.pickle\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l-nO5MNtdS1v",
        "NRU8CjtXdS15",
        "65Lj9pKtdS16"
      ],
      "name": "main.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('mlenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1f93c46dd61ce6925df2c3958a0a88f8277015b6331ee5021fc1dcace5372220"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
